#!/bin/bash
# ===========================================================================
# Script de backup automatique PostgreSQL - SantÃ© Rurale
# ===========================================================================
# Ce script effectue un backup chiffrÃ© de la base de donnÃ©es PostgreSQL
# et l'envoie vers un stockage S3 (MinIO ou AWS S3)
# ===========================================================================

set -euo pipefail  # ArrÃªter en cas d'erreur

# ===========================================================================
# CONFIGURATION
# ===========================================================================

# Charger les variables d'environnement
if [ -f .env.production ]; then
    export $(grep -v '^#' .env.production | xargs)
elif [ -f .env ]; then
    export $(grep -v '^#' .env | xargs)
else
    echo "âŒ Fichier .env introuvable"
    exit 1
fi

# Configuration
BACKUP_DIR="/var/backups/sante-rurale"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="sante_rurale_backup_${TIMESTAMP}.sql.gz"
BACKUP_PATH="${BACKUP_DIR}/${BACKUP_FILE}"
RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}

# Logs
LOG_FILE="${BACKUP_DIR}/backup.log"
mkdir -p "${BACKUP_DIR}"

# ===========================================================================
# FONCTIONS
# ===========================================================================

log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

error() {
    log "âŒ ERREUR: $1"
    exit 1
}

# ===========================================================================
# VÃ‰RIFICATIONS PRÃ‰-BACKUP
# ===========================================================================

log "ğŸš€ DÃ©marrage du backup PostgreSQL..."

# VÃ©rifier que pg_dump est disponible
if ! command -v pg_dump &> /dev/null; then
    error "pg_dump n'est pas installÃ©. Installez postgresql-client."
fi

# VÃ©rifier les variables d'environnement critiques
if [ -z "${POSTGRES_USER:-}" ] || [ -z "${POSTGRES_PASSWORD:-}" ] || [ -z "${POSTGRES_DB:-}" ]; then
    error "Variables PostgreSQL manquantes (POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB)"
fi

# ===========================================================================
# BACKUP DE LA BASE DE DONNÃ‰ES
# ===========================================================================

log "ğŸ“¦ CrÃ©ation du dump PostgreSQL..."

# DÃ©finir le mot de passe pour pg_dump
export PGPASSWORD="${POSTGRES_PASSWORD}"

# ExÃ©cuter le dump
if pg_dump \
    --host="${POSTGRES_HOST:-localhost}" \
    --port="${POSTGRES_PORT:-5432}" \
    --username="${POSTGRES_USER}" \
    --dbname="${POSTGRES_DB}" \
    --format=plain \
    --no-owner \
    --no-acl \
    --clean \
    --if-exists \
    | gzip > "${BACKUP_PATH}"; then
    log "âœ… Dump crÃ©Ã© avec succÃ¨s: ${BACKUP_FILE}"
else
    error "Ã‰chec de la crÃ©ation du dump PostgreSQL"
fi

# Nettoyer la variable d'environnement
unset PGPASSWORD

# VÃ©rifier que le fichier existe et n'est pas vide
if [ ! -s "${BACKUP_PATH}" ]; then
    error "Le fichier de backup est vide ou n'existe pas"
fi

# Afficher la taille du backup
BACKUP_SIZE=$(du -h "${BACKUP_PATH}" | cut -f1)
log "ğŸ“Š Taille du backup: ${BACKUP_SIZE}"

# ===========================================================================
# CHIFFREMENT DU BACKUP (optionnel)
# ===========================================================================

if [ -n "${BACKUP_ENCRYPTION_KEY:-}" ] && [ "${BACKUP_ENCRYPTION_KEY}" != "GÃ‰NÃ‰RER_UNE_CLÃ‰_SÃ‰PARÃ‰E" ]; then
    log "ğŸ” Chiffrement du backup..."

    if ! command -v openssl &> /dev/null; then
        log "âš ï¸  OpenSSL non disponible, backup non chiffrÃ©"
    else
        ENCRYPTED_FILE="${BACKUP_PATH}.enc"

        if openssl enc -aes-256-cbc \
            -salt \
            -in "${BACKUP_PATH}" \
            -out "${ENCRYPTED_FILE}" \
            -k "${BACKUP_ENCRYPTION_KEY}"; then

            # Remplacer le fichier non chiffrÃ© par le fichier chiffrÃ©
            rm "${BACKUP_PATH}"
            mv "${ENCRYPTED_FILE}" "${BACKUP_PATH}"
            log "âœ… Backup chiffrÃ© avec succÃ¨s"
        else
            log "âš ï¸  Ã‰chec du chiffrement, backup conservÃ© non chiffrÃ©"
        fi
    fi
fi

# ===========================================================================
# UPLOAD VERS S3 / MinIO (optionnel)
# ===========================================================================

if command -v aws &> /dev/null && [ -n "${BACKUP_S3_BUCKET:-}" ]; then
    log "â˜ï¸  Upload vers S3..."

    # Configuration pour MinIO (si utilisÃ©)
    if [ -n "${MINIO_ENDPOINT:-}" ]; then
        export AWS_ACCESS_KEY_ID="${MINIO_ROOT_USER}"
        export AWS_SECRET_ACCESS_KEY="${MINIO_ROOT_PASSWORD}"
        S3_ENDPOINT_URL="--endpoint-url http://${MINIO_ENDPOINT}"
    else
        S3_ENDPOINT_URL=""
    fi

    if aws s3 cp \
        "${BACKUP_PATH}" \
        "s3://${BACKUP_S3_BUCKET}/backups/${BACKUP_FILE}" \
        ${S3_ENDPOINT_URL}; then
        log "âœ… Backup uploadÃ© vers S3: ${BACKUP_S3_BUCKET}/backups/${BACKUP_FILE}"
    else
        log "âš ï¸  Ã‰chec de l'upload S3, backup conservÃ© localement"
    fi
else
    log "â„¹ï¸  Pas de configuration S3, backup conservÃ© localement uniquement"
fi

# ===========================================================================
# NETTOYAGE DES ANCIENS BACKUPS
# ===========================================================================

log "ğŸ§¹ Nettoyage des backups de plus de ${RETENTION_DAYS} jours..."

# Nettoyer les backups locaux
find "${BACKUP_DIR}" -name "sante_rurale_backup_*.sql.gz*" -type f -mtime +${RETENTION_DAYS} -delete
DELETED_COUNT=$(find "${BACKUP_DIR}" -name "sante_rurale_backup_*.sql.gz*" -type f -mtime +${RETENTION_DAYS} | wc -l)

if [ "${DELETED_COUNT}" -gt 0 ]; then
    log "ğŸ—‘ï¸  ${DELETED_COUNT} ancien(s) backup(s) local(aux) supprimÃ©(s)"
fi

# Nettoyer les backups S3 (si configurÃ©)
if command -v aws &> /dev/null && [ -n "${BACKUP_S3_BUCKET:-}" ]; then
    # Liste les fichiers de plus de RETENTION_DAYS jours
    OLD_DATE=$(date -d "${RETENTION_DAYS} days ago" +%Y%m%d 2>/dev/null || date -v -${RETENTION_DAYS}d +%Y%m%d)

    aws s3 ls "s3://${BACKUP_S3_BUCKET}/backups/" ${S3_ENDPOINT_URL} | \
    awk '{print $4}' | \
    grep "sante_rurale_backup_" | \
    while read -r file; do
        file_date=$(echo "$file" | grep -oP '\d{8}' | head -1)
        if [ "${file_date}" -lt "${OLD_DATE}" ]; then
            aws s3 rm "s3://${BACKUP_S3_BUCKET}/backups/${file}" ${S3_ENDPOINT_URL}
            log "ğŸ—‘ï¸  Backup S3 supprimÃ©: ${file}"
        fi
    done
fi

# ===========================================================================
# VÃ‰RIFICATION D'INTÃ‰GRITÃ‰
# ===========================================================================

log "ğŸ” VÃ©rification de l'intÃ©gritÃ© du backup..."

# VÃ©rifier que le fichier gzip est valide
if gzip -t "${BACKUP_PATH}" 2>/dev/null; then
    log "âœ… IntÃ©gritÃ© du backup vÃ©rifiÃ©e"
else
    error "Le backup est corrompu !"
fi

# ===========================================================================
# RÃ‰SUMÃ‰
# ===========================================================================

log "âœ… Backup terminÃ© avec succÃ¨s !"
log "ğŸ“ Fichier: ${BACKUP_FILE}"
log "ğŸ“Š Taille: ${BACKUP_SIZE}"

# Afficher le nombre de backups conservÃ©s
BACKUP_COUNT=$(find "${BACKUP_DIR}" -name "sante_rurale_backup_*.sql.gz*" -type f | wc -l)
log "ğŸ’¾ Nombre de backups conservÃ©s localement: ${BACKUP_COUNT}"

exit 0
